{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpyro import optim\n",
    "import numpyro\n",
    "\n",
    "import jax.numpy as jnp\n",
    "import jax\n",
    "import yaml\n",
    "import os\n",
    "import sys\n",
    "\n",
    "\n",
    "sys.path.insert(1,'..')\n",
    "import loader\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_params = {\n",
    "    'file': '/mnt/home/anejatbakhsh/ceph/ibl',\n",
    "    'tag': '2022_Q2_IBL_et_al_RepeatedSite',\n",
    "    'probe': 'probe00',\n",
    "    'sessions': [0,1,2],\n",
    "    'areas': ['CA1','DG','LP','PO','VISa'],\n",
    "    'props':{'train':.6,'test':.2,'validation':.2},\n",
    "    'seeds':{'train':0,'test':1,'validation':2},\n",
    "    'n_neurons': None, # all neurons\n",
    "    'n_trials': None, # all trials\n",
    "    'pre_time':0,\n",
    "    'post_time':.2,\n",
    "    'align_to': 'responses',\n",
    "    'train_trial_prop':.9, \n",
    "    'train_condition_prop':1, \n",
    "    'seed':0\n",
    "}\n",
    "\n",
    "dataloader = loader.IBLDataLoader(\n",
    "    dataset_params\n",
    ")\n",
    "\n",
    "xs,ys,rs,cs = dataloader.load_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[print('Trials:{}, Conditions:{}, Neurons:{}'.format(y.shape[0],y.shape[1],y.shape[2])) for y in ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "save=False\n",
    "file='../results/wishart/'\n",
    "\n",
    "model_params = {\n",
    "    'prior': 'WishartLRDProcess',\n",
    "    'seed': 0,\n",
    "    'nu': 0,\n",
    "\n",
    "    'gp_kernel_diag': 0.001,\n",
    "    'gp_kernel': [{\n",
    "        'type': 'RBF',\n",
    "        'scale': 1,\n",
    "        'sigma': 20.,\n",
    "        'normalizer': 100\n",
    "        }\n",
    "    ],\n",
    "    \n",
    "    'wp_sample_diag': 1.,\n",
    "  \n",
    "    'optimize_L': False,\n",
    "    'wp_kernel_diag': 0.001,\n",
    "    'wp_kernel': [{\n",
    "        'type': 'RBF',\n",
    "        'scale': 1,\n",
    "        'sigma': 50.,\n",
    "        'normalizer': 100\n",
    "        }\n",
    "    ],\n",
    "    'likelihood': 'NormalConditionalLikelihood' \n",
    "}\n",
    "\n",
    "variational_params = {\n",
    "    'guide': 'VariationalNormal',\n",
    "    'num_particles': 1,\n",
    "    'n_iter': 50000,\n",
    "    'optimizer':{\n",
    "        'type': 'Adam',\n",
    "        'step_size': 0.001\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs Wishart installed and added to the path\n",
    "# https://github.com/neurostatslab/wishart-process\n",
    "path = '/mnt/home/anejatbakhsh/Desktop/Projects/'\n",
    "sys.path.insert(1,path+'Wishart-Process/codes/')\n",
    "\n",
    "import models\n",
    "import inference\n",
    "import utils\n",
    "import evaluation\n",
    "import visualizations\n",
    "\n",
    "x,y,r,c = xs[0],ys[0],rs[0],cs[0]\n",
    "\n",
    "gp_kernel = utils.get_kernel(\n",
    "    model_params['gp_kernel'],\n",
    "    model_params['gp_kernel_diag']\n",
    ")\n",
    "D = y.shape[2]\n",
    "\n",
    "print('Trials, Conditions, Neurons: ', y.shape)\n",
    "\n",
    "\n",
    "gp = models.GaussianProcess(kernel=gp_kernel,num_dims=D)\n",
    "empirical = jnp.cov((y - y.mean(0)[None]).reshape(y.shape[0]*y.shape[1],y.shape[2]).T)\n",
    "\n",
    "wp_kernel = utils.get_kernel(\n",
    "    model_params['wp_kernel'],\n",
    "    model_params['wp_kernel_diag']\n",
    ")\n",
    "\n",
    "\n",
    "V = empirical+model_params['wp_sample_diag']*jnp.eye(D)\n",
    "\n",
    "wp = models.WishartLRDProcess(\n",
    "    kernel=wp_kernel,nu=model_params['nu'] ,\n",
    "    V=V,optimize_L=model_params['optimize_L'],\n",
    "    diag_scale=wp_sample_diag\n",
    ")\n",
    "\n",
    "likelihood = eval('models.'+model_params['likelihood'])(D)\n",
    "joint = models.JointGaussianWishartProcess(gp,wp,likelihood) \n",
    "\n",
    "print(gp.evaluate_kernel(x,x).max())\n",
    "print(wp.evaluate_kernel(x,x).max())\n",
    "\n",
    "compared = evaluation.compare(y)\n",
    "compared['grand-empirical'] = jnp.repeat(empirical[:,:,None],y.shape[1],2)\n",
    "\n",
    "\n",
    "# %%\n",
    "\n",
    "mu_empirical = y.mean(0)\n",
    "sigma_empirical = compared['empirical'].transpose(2,0,1)\n",
    "visualizations.visualize_pc(\n",
    "    mu_empirical[:,None],\n",
    "    .1*sigma_empirical,\n",
    "    pc=y.reshape(y.shape[0]*y.shape[1],-1),\n",
    "    dotsize=500,\n",
    "    linewidth=2,\n",
    "    fontsize=30\n",
    ")\n",
    "\n",
    "# %%\n",
    "init = {'G':y.mean(0).T[:,None]}\n",
    "\n",
    "varfam = eval('inference.'+variational_params['guide'])(\n",
    "    joint.model,init=init\n",
    ")\n",
    "optimizer = eval('optim.'+variational_params['optimizer']['type'])(\n",
    "    variational_params['optimizer']['step_size']\n",
    ")\n",
    "key = jax.random.PRNGKey(seed)\n",
    "\n",
    "varfam.infer(\n",
    "    optimizer,x,y,\n",
    "    n_iter=variational_params['n_iter'],key=key,\n",
    "    num_particles=variational_params['num_particles']\n",
    ")\n",
    "joint.update_params(varfam.posterior)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "posterior = models.NormalGaussianWishartPosterior(joint,varfam,x)\n",
    "with numpyro.handlers.seed(rng_seed=seed):\n",
    "    mu_hat, sigma_hat, F_hat = posterior.mode(x)\n",
    "    mu_prime, sigma_prime = posterior.derivative(x)\n",
    "    log_pf, log_pg = posterior.posterior.log_prob(F=F_hat,G=mu_hat.T[:,None])\n",
    "\n",
    "mus[index] = mu_hat.copy()\n",
    "sigmas[index] = sigma_hat.copy()\n",
    "\n",
    "# %%\n",
    "visualizations.plot_loss(\n",
    "    [varfam.losses],xlabel='Iteration',ylabel='ELBO',\n",
    "    titlestr='Training Loss',colors=['k'],\n",
    ")\n",
    "# %%\n",
    "visualizations.visualize_pc(\n",
    "    mu_hat[:,None],.1*sigma_hat,\n",
    "    pc_test=y_test.reshape(y_test.shape[0]*y_test.shape[1],-1),\n",
    "    dotsize=500,\n",
    "    linewidth=2,\n",
    "    fontsize=30\n",
    ")\n",
    "# %%\n",
    "var_bootstrap = jnp.array([jnp.concatenate((y[:i],y[i+1:])).var(0) for i in range(y.shape[0])])\n",
    "\n",
    "# %%\n",
    "visualizations.plot_variance_smoothness(\n",
    "    x[:,None],[\n",
    "        y.var(0),\n",
    "        jnp.array([jnp.diag(compared['lw'][:,:,i]) for i in range(len(x))]),\n",
    "        jnp.array([jnp.diag(compared['grand-empirical'][:,:,i]) for i in range(len(x))]),\n",
    "        jnp.array([jnp.diag(sigma_hat[i]) for i in range(len(x))]),\n",
    "    ],\n",
    "    yerr=var_bootstrap,\n",
    "    methods=['empirical','lw','grand-empirical','wishart']\n",
    ")\n",
    "# %%\n",
    "compared['wishart'] = sigma_hat.transpose(1,2,0)\n",
    "lpp = {}\n",
    "mu_empirical = y.mean(0)\n",
    "\n",
    "for key in compared.keys():\n",
    "    lpp[key] = likelihood.log_prob(y_test,mu_empirical,compared[key].transpose(2,0,1)).flatten()\n",
    "\n",
    "\n",
    "visualizations.plot_box(\n",
    "    lpp,titlestr='Log Posterior Predictive',\n",
    ")\n",
    "\n",
    "[print(key, jnp.median(lpp[key])) for key in lpp.keys()]\n",
    "print(jnp.median(jnp.exp(lpp['wishart']-lpp['grand-empirical'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_neural = utils.ssd([\n",
    "    [[mus[i],sigmas[i]], \n",
    "     [mus[j],sigmas[j]]]\n",
    "     for i in range(len(ys)) \n",
    "     for j in range(len(ys))],\n",
    "    alpha=2.,\n",
    "    niter=1000\n",
    ")\n",
    "\n",
    "dist_rt = utils.ssd([\n",
    "    [[rts[i].mean(0)[:,None], rts[i].var(0)[:,None,None]],\n",
    "     [rts[j].mean(0)[:,None], rts[j].var(0)[:,None,None]]]\n",
    "    for i in range(len(ys)) \n",
    "    for j in range(len(ys))],\n",
    "    alpha=2.,\n",
    "    niter=1000\n",
    ")\n",
    "\n",
    "dist_cc = utils.ssd([\n",
    "    [[ccs[i].mean(0)[:,None], ccs[i].var(0)[:,None,None]],\n",
    "     [ccs[j].mean(0)[:,None], ccs[j].var(0)[:,None,None]]]\n",
    "    for i in range(len(ys)) \n",
    "    for j in range(len(ys))],\n",
    "    alpha=2.,\n",
    "    niter=1000\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jaxenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
